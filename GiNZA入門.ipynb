{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U ginza ja-ginza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 本ページのコードは、https://note.com/npaka/n/n5c3e4ca67956をベースとしている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GiNZAはspacy上に日本語をの自然言語処理機能を実装したものである。したがって、日本語を解析するためには、 \"ja_ginza\"を指定することが必要である。\n",
    "### GiNZAの形態素解析は、MeCabやJUMANと異なり、三つのモードで解析することができる。まず、デフォルトの設定のまま行う例を示す。次のように「コロナ禍」「新型コロナウイルス感染症」「危機的状況」がそれぞれ一つ独立したトークンとして返される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コロナ禍\n",
      "と\n",
      "は\n",
      "、\n",
      "2019\n",
      "年\n",
      "末\n",
      "から\n",
      "の\n",
      "新型コロナウイルス感染症\n",
      "の\n",
      "流行\n",
      "に\n",
      "よる\n",
      "災難\n",
      "や\n",
      "危機的状況\n",
      "を\n",
      "指す\n",
      "言葉\n",
      "で\n",
      "ある\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "X = 'コロナ禍とは、2019年末からの新型コロナウイルス感染症の流行による災難や危機的状況を指す言葉である'\n",
    "doc = nlp(X)\n",
    "\n",
    "# 解析された形態素はtokenに格納されている。\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GiNZAの形態素解析のモードは関数ginza.set_split_mode()で指定する。例えば、「新型コロナウイルス感染症」は次のように三つのモードで分割することができる。デフォルトはCモードになっている。\n",
    "<br>\n",
    "A: 短い単位(新型/ 　コロナ/ 　ウイルス/ 　感染/ 　症)<br>\n",
    "B: 中間(新型/ 　コロナ/ 　ウイルス/ 　感染症)<br>\n",
    "C: 長い単位(新型コロナウイルス感染症)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コロナ\n",
      "禍\n",
      "と\n",
      "は\n",
      "、\n",
      "2019\n",
      "年\n",
      "末\n",
      "から\n",
      "の\n",
      "新型\n",
      "コロナ\n",
      "ウイルス\n",
      "感染\n",
      "症\n",
      "の\n",
      "流行\n",
      "に\n",
      "よる\n",
      "災難\n",
      "や\n",
      "危機\n",
      "的\n",
      "状況\n",
      "を\n",
      "指す\n",
      "言葉\n",
      "で\n",
      "ある\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import ginza\n",
    "nlp = spacy.load('ja_ginza')\n",
    "#次のコードでモード（A,B,C）を指定する。\n",
    "ginza.set_split_mode(nlp, \"A\")\n",
    "doc = nlp(X)\n",
    "\n",
    "# 形態素分割\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ja_ginzaで解析された形態素に関連する結果には、次のものがある。\n",
    "形態素番号 ：　token.i<br>\n",
    "形態素表層 ：　token.text<br>\n",
    "語の原型 　：　token.lenma_（レンマと呼ぶ）<br>\n",
    "形態素タグ1：  token.pos_(英語のタグ表記)<br>\n",
    "形態素タグ2：　token.tag_(日本語のタグ表記)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tコロナ禍\tコロナ禍\tNOUN\t名詞-普通名詞-一般\n",
      "1\tと\tと\tADP\t助詞-格助詞\n",
      "2\tは\tは\tADP\t助詞-係助詞\n",
      "3\t、\t、\tPUNCT\t補助記号-読点\n",
      "4\t2019\t2019\tNUM\t名詞-数詞\n",
      "5\t年\t年\tNOUN\t名詞-普通名詞-助数詞可能\n",
      "6\t末\t末\tNOUN\t接尾辞-名詞的-副詞可能\n",
      "7\tから\tから\tADP\t助詞-格助詞\n",
      "8\tの\tの\tADP\t助詞-格助詞\n",
      "9\t新型コロナウイルス感染症\t新型コロナウイルス感染症\tNOUN\t名詞-普通名詞-一般\n",
      "10\tの\tの\tADP\t助詞-格助詞\n",
      "11\t流行\t流行\tNOUN\t名詞-普通名詞-サ変可能\n",
      "12\tに\tに\tADP\t助詞-格助詞\n",
      "13\tよる\tよる\tVERB\t動詞-一般\n",
      "14\t災難\t災難\tNOUN\t名詞-普通名詞-一般\n",
      "15\tや\tや\tADP\t助詞-副助詞\n",
      "16\t危機的状況\t危機的状況\tNOUN\t名詞-普通名詞-一般\n",
      "17\tを\tを\tADP\t助詞-格助詞\n",
      "18\t指す\t指す\tVERB\t動詞-一般\n",
      "19\t言葉\t言葉\tNOUN\t名詞-普通名詞-一般\n",
      "20\tで\tだ\tAUX\t助動詞\n",
      "21\tある\tある\tVERB\t動詞-非自立可能\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "doc = nlp(X)\n",
    "\n",
    "# 形態素解析の結果の表示\n",
    "for sent in doc.sents:\n",
    "   for token in sent:\n",
    "       print(\n",
    "           str(token.i)+ \"\\t\"+ \n",
    "           token.text+ \"\\t\"+\n",
    "           token.lemma_+ \"\\t\"+\n",
    "           token.pos_+'\\t'+ \n",
    "           token.tag_\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GiNZAの品詞種類及びその日本語のタグ表記形態は次のようになっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・名詞-普通名詞-一般\n",
    "・名詞-普通名詞-サ変可能\n",
    "・名詞-普通名詞-形状詞可能\n",
    "・名詞-普通名詞-サ変形状詞可能\n",
    "・名詞-普通名詞-副詞可能\n",
    "・名詞-普通名詞-助数詞可能\n",
    "・名詞-固有名詞-一般\n",
    "・名詞-固有名詞-人名-一般\n",
    "・名詞-固有名詞-人名-姓\n",
    "・名詞-固有名詞-人名-名\n",
    "・名詞-固有名詞-地名-一般\n",
    "・名詞-固有名詞-地名-国\n",
    "・名詞-数詞\n",
    "・名詞-助動詞語幹\n",
    "・代名詞\n",
    "・形状詞-一般\n",
    "・形状詞-タリ\n",
    "・形状詞-助動詞語幹\n",
    "・連体詞\n",
    "・副詞\n",
    "・接続詞\n",
    "・感動詞-一般\n",
    "・感動詞-フィラー\n",
    "・動詞-一般\n",
    "・動詞-非自立可能\n",
    "・形容詞-一般\n",
    "・形容詞-非自立可能\n",
    "・助動詞\n",
    "・助詞-格助詞\n",
    "・助詞-副助詞\n",
    "・助詞-係助詞\n",
    "・助詞-接続助詞\n",
    "・助詞-終助詞\n",
    "・助詞-準体助詞\n",
    "・接頭辞\n",
    "・接尾辞-名詞的-一般\n",
    "・接尾辞-名詞的-サ変可能\n",
    "・接尾辞-名詞的-形状詞可能\n",
    "・接尾辞-名詞的-サ変形状詞可能\n",
    "・接尾辞-名詞的-副詞可能\n",
    "・接尾辞-名詞的-助数詞\n",
    "・接尾辞-形状詞的\n",
    "・接尾辞-動詞的\n",
    "・接尾辞-形容詞的\n",
    "・記号-一般\n",
    "・記号-文字\n",
    "・補助記号-一般\n",
    "・補助記号-句点\n",
    "・補助記号-読点\n",
    "・補助記号-括弧開\n",
    "・補助記号-括弧閉\n",
    "・補助記号-ＡＡ-一般\n",
    "・補助記号-ＡＡ-顔文字\n",
    "・空白"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GiNZAの品詞種類及びその英語のタグ表記形態は次のようになっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "・NOUN : 名詞\n",
    "　・名詞-普通名詞 (但しVERB,ADJとして使われるものを除く) (例: パン)\n",
    "・PROPN : 固有名詞\n",
    "　・名詞-固有名詞 (例: 北海道)\n",
    "・VERB : 動詞\n",
    "　・動詞(但し非自立となるものを除く) (例: 食べる)\n",
    "　・名刺+サ変可能で動詞の語尾が付いたもの (例: '食事'する)\n",
    "・ADJ : 形容詞\n",
    "　・形容詞(但し非自立となるものを除く) (例: 大きい)\n",
    "　・形状詞 (例: 豊か)\n",
    "　・連体詞(但しDETを除く) (例: 大きな)\n",
    "　・名詞-形状詞可能で形状詞の語尾が付く場合 (例: '自由'な)\n",
    "・ADV : 副詞\n",
    "　・副詞 (例: ゆっくり)\n",
    "・INTJ : 間投詞\n",
    "　・間投詞 (例: あっ)\n",
    "\n",
    "・PRON : 代名詞\n",
    "　・代名詞 (例: 私)\n",
    "・NUM : 数詞\n",
    "　・名詞-数詞 (例: 5)\n",
    "・AUX : 助動詞\n",
    "　・助動詞 (例: た)\n",
    "　・動詞/形容詞のうち非自立のもの (例: して'いる', 食べ'にくい’)\n",
    "・CONJ : 接続詞\n",
    "　・接続詞または助詞-接続助詞のうち、等位接 続詞として用いるもの (例: と)\n",
    "・SCONJ : 従属接続詞\n",
    "　・接続詞・助詞-接続助詞(CONJとなるものを除く) (例: て)\n",
    "　・準体助詞 (例: 行く'の'が)\n",
    "・DET : 限定詞\n",
    "　・連体詞の一部 (例: この, その, あんな, どんな)\n",
    "・ADP : 接置詞\n",
    "　・助詞-格助詞 (例: が)\n",
    "　・副助詞 (例: しか)\n",
    "　・係助詞 (例: こそ)\n",
    "・PART : 接辞\n",
    "　・助詞-終助詞 (例: 何時です'か')\n",
    "　・接尾辞 (例: 深'さ')\n",
    "\n",
    "・PUNCT : 句読点\n",
    "　・補助記号-句点/読点/括弧開/括弧閉\n",
    "・SYM : 記号\n",
    "　・記号・補助記号のうちPUNCT以外のもの\n",
    "・X : その他\n",
    "　・空白"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 品詞を指定してトークンを返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コロナ禍\n",
      "2019\n",
      "年\n",
      "新型コロナウイルス感染症\n",
      "流行\n",
      "よる\n",
      "災難\n",
      "危機的状況\n",
      "指す\n",
      "言葉\n",
      "ある\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "doc = nlp(X)\n",
    "\n",
    "pos = [\"名詞\",\"動詞\"]\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        #print(token.text + \"\\t\" +token.tag_)\n",
    "        i = (token.tag_.split(\"-\"))[0]\n",
    "        if i in pos:\n",
    "            print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 語・文節の係り受け解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日本語の構文解析でよく知られている解析器としては文節係り受け関係解析を行うCabochaとJUMA/KNPである。GiNZAは文節の係り受けだけではなく、語・形態素の係り受けも解析する。\n",
    "\n",
    "解析して結果を視覚化した例を次に示す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ja\" id=\"6287b4bb7ae747ed8bc3d4255d8b84a2-0\" class=\"displacy\" width=\"930\" height=\"297.0\" direction=\"ltr\" style=\"max-width: none; height: 297.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">田中</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"130\">太郎</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"130\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"210\">は</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"210\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">友達</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"370\">と</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"370\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">一緒</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">に</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">学校</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"690\">に</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"690\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">行っ</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">た。</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-0\" stroke-width=\"2px\" d=\"M70,162.0 C70,122.0 115.0,122.0 115.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,164.0 L62,152.0 78,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-1\" stroke-width=\"2px\" d=\"M150,162.0 C150,2.0 770.0,2.0 770.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M150,164.0 L142,152.0 158,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-2\" stroke-width=\"2px\" d=\"M150,162.0 C150,122.0 195.0,122.0 195.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M195.0,164.0 L203.0,152.0 187.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-3\" stroke-width=\"2px\" d=\"M310,162.0 C310,82.0 440.0,82.0 440.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310,164.0 L302,152.0 318,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-4\" stroke-width=\"2px\" d=\"M310,162.0 C310,122.0 355.0,122.0 355.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M355.0,164.0 L363.0,152.0 347.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-5\" stroke-width=\"2px\" d=\"M470,162.0 C470,42.0 765.0,42.0 765.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M470,164.0 L462,152.0 478,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-6\" stroke-width=\"2px\" d=\"M470,162.0 C470,122.0 515.0,122.0 515.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M515.0,164.0 L523.0,152.0 507.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-7\" stroke-width=\"2px\" d=\"M630,162.0 C630,82.0 760.0,82.0 760.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M630,164.0 L622,152.0 638,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-8\" stroke-width=\"2px\" d=\"M630,162.0 C630,122.0 675.0,122.0 675.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M675.0,164.0 L683.0,152.0 667.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-9\" stroke-width=\"2px\" d=\"M790,162.0 C790,122.0 835.0,122.0 835.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6287b4bb7ae747ed8bc3d4255d8b84a2-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M835.0,164.0 L843.0,152.0 827.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza')\n",
    "X2 = \"田中太郎は友達と一緒に学校に行った。\"\n",
    "doc = nlp(X2)\n",
    "\n",
    "# 係り受け関係グラフ\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'compact':False,'distance': 80})\n",
    "\n",
    "#「行った」文節のかかる先「太郎は」と「一緒に」「学校に」文節であることが分かる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文節係り受け解析の結果はginza.bunsetu_spans()に格納されている。文節は次のように返すことができる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "田中太郎は\n",
      "友達と\n",
      "一緒に\n",
      "学校に\n",
      "行った。\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import ginza\n",
    "\n",
    "nlp = spacy.load('ja_ginza')\n",
    "doc = nlp(X2)\n",
    "\n",
    "#文節を返す\n",
    "for sent in doc.sents:\n",
    "    for span in ginza.bunsetu_spans(sent):\n",
    "        print(span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文節の係り受け関係の情報は、次の項目に分かれている。\n",
    "token.dep_ : 構文従属関係<br>\n",
    "token.head : 構文上の親のトークン<br>\n",
    "token.children : 構文上の子のトークン<br>\n",
    "token.lefts : 構文上の左の文節<br>\n",
    "token.rights : 構文上の右の文節<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "田中\tcompound\n",
      "太郎\tnsubj\n",
      "は\tcase\n",
      "友達\tnmod\n",
      "と\tcase\n",
      "一緒\tobl\n",
      "に\tcase\n",
      "学校\tobl\n",
      "に\tcase\n",
      "行っ\tROOT\n",
      "た\taux\n",
      "。\tpunct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import ginza\n",
    "\n",
    "nlp = spacy.load('ja_ginza')\n",
    "doc = nlp(X2)\n",
    "\n",
    "#文節を返す\n",
    "for sent in doc.sents:\n",
    "    for span in ginza.bunsetu_spans(sent):\n",
    "        for token in span:\n",
    "            print(str(token)+ \"\\t\" +str(token.dep_))\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "田中太郎は\tcompound\n",
      "田中太郎は\tnsubj\n",
      "田中太郎は\tcase\n",
      "友達と\tnmod\n",
      "友達と\tcase\n",
      "一緒に\tobl\n",
      "一緒に\tcase\n",
      "学校に\tobl\n",
      "学校に\tcase\n",
      "行った。\tROOT\n",
      "行った。\taux\n",
      "行った。\tpunct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import ginza\n",
    "\n",
    "nlp = spacy.load('ja_ginza')\n",
    "doc = nlp(X2)\n",
    "\n",
    "#文節を返す\n",
    "for sent in doc.sents:\n",
    "    for span in ginza.bunsetu_spans(sent):\n",
    "        for token in span:\n",
    "            print(str(span)+ \"\\t\" +str(token.dep_))\n",
    "\n",
    "#文節によっては複数の文節と係り受け関係を持っている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "友達と\t nmod\t一緒に\n",
      "田中太郎は\t nsubj\t行った。\n",
      "一緒に\t obl\t行った。\n",
      "学校に\t obl\t行った。\n"
     ]
    }
   ],
   "source": [
    "#import spacy\n",
    "#import ginza\n",
    "\n",
    "#nlp = spacy.load('ja_ginza')\n",
    "#doc = nlp(X2)\n",
    "\n",
    "#文節間の係り受け解析\n",
    "for sent in doc.sents:\n",
    "    for span in ginza.bunsetu_spans(sent):\n",
    "        for token in span.lefts:\n",
    "            print(str(ginza.bunsetu_span(token))+ \"\\t\", str(token.dep_)+ \"\\t\" +str(span))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定した品詞が含む文節のみ返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "田中太郎\n",
      "友達\n",
      "一緒\n",
      "学校\n"
     ]
    }
   ],
   "source": [
    "#名詞が含む文節の中から付属語を除いたものを返す。\n",
    "for noun in doc.noun_chunks:\n",
    "    print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "田中太郎,Person,0,4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    田中太郎\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Person</span>\n",
       "</mark>\n",
       "は友達と一緒に学校に行った。</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "doc = nlp(X2)\n",
    "\n",
    "# 固有表現抽出\n",
    "for ent in doc.ents:\n",
    "   print(\n",
    "       ent.text+','+ # テキスト\n",
    "       ent.label_+','+ # ラベル\n",
    "       str(ent.start_char)+','+ # 開始位置\n",
    "       str(ent.end_char)) # 終了位置\n",
    "\n",
    "# 強調表示\n",
    "displacy.render(doc, style='ent', jupyter=True, options={'distance': 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日\n",
      "金曜日\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# _*_ coding: utf-8 _*_\n",
    "import spacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "word_list = []\n",
    "\n",
    "def tokens(sentences, pos = [\"名詞\", \"形状詞\",\"動詞\"], stopwords_list = []):\n",
    "    doc = nlp(sentences)\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            k = (token.tag_.split(\"-\"))[0]\n",
    "            if k in pos:\n",
    "                print(token.lemma_)\n",
    "    return word_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    out = tokens('今日は金曜日です')\n",
    "    print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'my_ginza'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmy_ginza\u001b[39;00m\n\u001b[0;32m      3\u001b[0m word_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m out \u001b[38;5;241m=\u001b[39mmy_ginza\u001b[38;5;241m.\u001b[39mtokens(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m今日は金曜日です\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'my_ginza'"
     ]
    }
   ],
   "source": [
    "import my_ginza\n",
    "\n",
    "word_list = []\n",
    "out =my_ginza.tokens('今日は金曜日です')\n",
    "print(out)\n",
    "\n",
    "word_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x0000020725DE72E0>)\n",
      "('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x00000207386D1700>)\n",
      "('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x00000207386D18C0>)\n",
      "('morphologizer', <spacy.pipeline.morphologizer.Morphologizer object at 0x00000207386DC640>)\n",
      "('compound_splitter', <ginza.compound_splitter.CompoundSplitter object at 0x00000207386E3850>)\n",
      "('bunsetu_recognizer', <ginza.bunsetu_recognizer.BunsetuRecognizer object at 0x00000207386E1FC0>)\n"
     ]
    }
   ],
   "source": [
    "for p in nlp.pipeline:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "田中\n",
      "太郎\n",
      "は\n",
      "友達\n",
      "と\n",
      "一緒\n",
      "に\n",
      "学校\n",
      "に\n",
      "行っ\n",
      "た\n",
      "。\n"
     ]
    }
   ],
   "source": [
    "texts =list(nlp.pipe([X2]))\n",
    "for sents in texts:\n",
    "    for sent in sents.sents:\n",
    "        #文単位で分割される\n",
    "        for token in sent:\n",
    "             print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
